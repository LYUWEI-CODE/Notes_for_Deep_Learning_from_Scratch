{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480bb3d4",
   "metadata": {},
   "source": [
    "卷积神经网络(Convolutional Neural Network, CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1df51",
   "metadata": {},
   "source": [
    "卷积层(Convolution层)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fbd82",
   "metadata": {},
   "source": [
    "- 全连接层存在的问题：数据的形状被“忽视”了。全连接层输入时，需要将3维数据拉平为1维数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e07a1",
   "metadata": {},
   "source": [
    "卷积运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f99344",
   "metadata": {},
   "source": [
    "- 卷积运算对输入数据应用滤波器（核）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a4041",
   "metadata": {},
   "source": [
    "- CNN中，滤波器的参数就对应之前的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681aa92",
   "metadata": {},
   "source": [
    "填充(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437120e",
   "metadata": {},
   "source": [
    "- 在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比\n",
    "如0等），这称为填充（padding）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02786fbe",
   "metadata": {},
   "source": [
    "- 使用填充主要是为了调整输出的大小。比如，对大小为(4,4)的输入数据应用(3,3)的滤波器时，输出大小变为(2,2)，相当于输出大小比输入大小缩小了2个元素。这在反复进行多次卷积运算的深度网络中会成为问题。为什么呢？因为如果每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为1，导致无法再应用卷积运算。为了避免出现这样的情况，就要使用填充。在刚才的例子中，将填充的幅度设为1，那么相对于输入大小(4,4)，输出大小也保持为原来的(4,4)。因此，卷积运算就可以在保持空间大小不变的情况下将数据传给下一层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dffa2",
   "metadata": {},
   "source": [
    "步幅(stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee187da",
   "metadata": {},
   "source": [
    "- 应用滤波器的位置间隔称为步幅（stride）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549ef05",
   "metadata": {},
   "source": [
    "- 假设输入大小为(H,W)，滤波器大小为(FH,FW)，输出大小为(OH,OW)，填充为P，步幅为S。此时，输出大小可通过下式进行计算：\n",
    "\t\n",
    "\t$OH=\\dfrac{H+2P-FH}{S}+1$\n",
    "\t\n",
    "\t$OW=\\dfrac{W+2P-FW}{S}+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48299577",
   "metadata": {},
   "source": [
    "- 当输出大小无法除尽时（结果是小数时），需要采取报错等对"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ee869",
   "metadata": {},
   "source": [
    "池化层(pooling层)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747fa4ac",
   "metadata": {},
   "source": [
    "- 池化是缩小高、长方向上的空间的运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea094d",
   "metadata": {},
   "source": [
    "- 除了Max池化之外，还有Average池化等。相对于Max池化是从目标区域中取出最大值，Average池化则是计算目标区域的平均值。在图像识别领域，主要使用Max池化。因此，本书中说到“池化层”时，指的是Max池化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bc3f0",
   "metadata": {},
   "source": [
    "- 池化层的特征：没有要学习的参数、通道数不发生变化、对微笑的位置变化具有鲁棒性（健壮）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336975bb",
   "metadata": {},
   "source": [
    "基于im2col的展开"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55c5c1",
   "metadata": {},
   "source": [
    "- im2col是一个函数，将输入数据展开以适合滤波器（权重） "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d20de9",
   "metadata": {},
   "source": [
    "- im2col 这个名称是“image to column”的缩写，翻译过来就是“从图像到矩阵”的意思。Caffe、Chainer等深度学习框架中有名为im2col的函数，并且在卷积层的实现中，都使用了im2col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14728e",
   "metadata": {},
   "source": [
    "具有代理性的CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d92f90",
   "metadata": {},
   "source": [
    "- LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fe7a2",
   "metadata": {},
   "source": [
    "- AlexNet:引发深度学习热潮的导火线"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
